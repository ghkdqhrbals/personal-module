package org.ghkdqhrbals.client.ai

import org.ghkdqhrbals.client.config.log.logger
import java.util.concurrent.atomic.AtomicInteger
import com.fasterxml.jackson.annotation.JsonInclude
import com.fasterxml.jackson.annotation.JsonInclude.Include
import io.github.resilience4j.circuitbreaker.annotation.CircuitBreaker
import org.ghkdqhrbals.client.config.log.setting
import org.ghkdqhrbals.model.domain.Jackson
import org.springframework.stereotype.Component
import org.springframework.web.reactive.function.client.WebClient

/**
 * Ollama ë¡œì»¬ ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” LLM í´ë¼ì´ì–¸íŠ¸ - WebClient ê¸°ë°˜ + Circuit Breaker
 */
open class OllamaClientImpl(
    private val modelName: String,
    private val ollamaUrl: String,
    private val webClient: WebClient
) : LlmClient {

    override val name: LlmClientType = LlmClientType.OLLAMA
    init {
        logger().setting("ollamaUrl=$ollamaUrl, modelName=$modelName")
    }

    private val activeRequests = AtomicInteger(0)
    private val totalRequests = AtomicInteger(0)
    private val completedRequests = AtomicInteger(0)
    private val mapper = Jackson.getMapper()

    @JsonInclude(Include.NON_NULL)
    data class OllamaChatRequest(
        val model: String,
        val messages: List<OllamaChatMessage>,
        val temperature: Double? = null,
        val stream: Boolean = false
    )

    data class OllamaChatMessage(
        val role: String,
        val content: String
    )

    data class OllamaChatResponse(
        val model: String,
        val created_at: String,
        val message: OllamaChatMessage,
        val done: Boolean,
        val done_reason: String? = null,
        val total_duration: Long? = null,
        val load_duration: Long? = null,
        val prompt_eval_count: Int? = null,
        val prompt_eval_duration: Long? = null,
        val eval_count: Int? = null,
        val eval_duration: Long? = null
    )

    @CircuitBreaker(name = "ollama", fallbackMethod = "circuitBreakerFallback")
    override suspend fun createChatCompletion(request: ChatRequest): ChatResponse {
        logger().info("ğŸ”Œ [Before] Ollama ìš”ì²­ ì‹œì‘")
        return try {
            val response = executeOllamaRequest(request)
            logger().info("ğŸ”Œ [After Success] Ollama ìš”ì²­ ì„±ê³µ")
            response
        } catch (e: io.github.resilience4j.circuitbreaker.CallNotPermittedException) {
            logger().error("ğŸ”Œ [Circuit Open] ìš”ì²­ ì°¨ë‹¨ë¨ - Circuitì´ OPEN ìƒíƒœ")
            throw e
        } catch (e: Exception) {
            logger().error("ğŸ”Œ [After Error] Ollama ìš”ì²­ ì‹¤íŒ¨: {}", e.message)
            throw e
        }
    }

    /**
     * Circuit Breaker fallback ë©”ì„œë“œ
     * Circuitì´ OPENëœ ê²½ìš° í˜¸ì¶œë¨
     */
    open fun circuitBreakerFallback(request: ChatRequest, e: Exception): ChatResponse {
        logger().warn("ğŸ”Œ [Fallback] Ollama ì„œë¹„ìŠ¤ ì´ìš© ë¶ˆê°€ - Circuitì´ OPENë¨")
        throw e
    }

    private fun executeOllamaRequest(request: ChatRequest): ChatResponse {
        val requestId = totalRequests.incrementAndGet()
        activeRequests.incrementAndGet()

        try {
            // OpenAI í˜•ì‹ messagesë¥¼ Ollama í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            val ollamaMessages = request.messages.map { msg ->
                OllamaChatMessage(role = msg.role, content = msg.content)
            }

            val ollamaRequest = OllamaChatRequest(
                model = modelName,
                messages = ollamaMessages,
                temperature = request.temperature
            )

            val startTime = System.currentTimeMillis()

            // /api/chat ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš© (role ì§€ì›)
            val responseBytes = webClient.post()
                .uri("$ollamaUrl/api/chat")
                .header("Content-Type", "application/json")
                .bodyValue(ollamaRequest)
                .retrieve()
                .bodyToMono(ByteArray::class.java)
                .block() ?: throw IllegalStateException("Ollama returned null response")

            val responseText = String(responseBytes)

            // NDJSON í˜•ì‹: ì—¬ëŸ¬ ì¤„ì˜ JSONì´ '\n'ìœ¼ë¡œ êµ¬ë¶„ë¨
            val lines = responseText.trim().lines().filter { it.isNotBlank() }
            val fullResponse = StringBuilder()
            var lastResponse: OllamaChatResponse? = null

            for (line in lines) {
                try {
                    val partial = mapper.readValue(line, OllamaChatResponse::class.java)
                    fullResponse.append(partial.message.content)
                    lastResponse = partial
                } catch (e: Exception) {
                    logger().warn("âš ï¸ Failed to parse Ollama response line: ${line.take(100)}")
                }
            }

            if (lastResponse == null || !lastResponse.done) {
                throw IllegalStateException("Ollama response incomplete - done=${lastResponse?.done}")
            }

            val elapsed = System.currentTimeMillis() - startTime
            completedRequests.incrementAndGet()

            logger().info("âœ… Ollama ìš”ì²­ #$requestId ì™„ë£Œ (${elapsed}ms, ${lastResponse.eval_count ?: 0} tokens)")

            val choice = Choice(
                message = Message(
                    role = "assistant",
                    content = fullResponse.toString()
                ),
                finishReason = lastResponse.done_reason ?: "stop"
            )

            return ChatResponse(
                id = "ollama-$requestId",
                choices = listOf(choice),
                usage = Usage(0, 0, 0)
            )

        } catch (e: Exception) {
            val completed = completedRequests.incrementAndGet()
            logger().error("âŒ Ollama ìš”ì²­ #$requestId ì‹¤íŒ¨ - [ì™„ë£Œ: $completed/${totalRequests.get()}] ${e.message}")
            throw e

        } finally {
            val remaining = activeRequests.decrementAndGet()
            logger().info("ğŸ”´ Ollama ìš”ì²­ #$requestId ì¢…ë£Œ (ë‚¨ì€ í™œì„±: $remaining)")
        }
    }
}

